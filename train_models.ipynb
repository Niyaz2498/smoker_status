{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d846b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db36cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('dataset/split_train.csv')\n",
    "X = df.drop('smoking', axis=1)  # Features\n",
    "y = df['smoking']  # Target\n",
    "\n",
    "# train-test split (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6968fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies to avoid modifying original data\n",
    "X_train_processed = X_train.copy()\n",
    "X_test_processed = X_test.copy()\n",
    "\n",
    "# Standard Scaling \n",
    "scaling_features = ['age', 'height(cm)', 'weight(kg)', 'waist(cm)', 'systolic', 'relaxation', 'hemoglobin']\n",
    "scaler = StandardScaler()\n",
    "X_train_processed[scaling_features] = scaler.fit_transform(X_train_processed[scaling_features])\n",
    "X_test_processed[scaling_features] = scaler.transform(X_test_processed[scaling_features])\n",
    "\n",
    "# Log Transformation\n",
    "log_features = ['AST', 'ALT', 'Gtp', 'fasting blood sugar', 'triglyceride']\n",
    "for feature in log_features:\n",
    "    X_train_processed[feature] = np.log1p(X_train_processed[feature])\n",
    "    X_test_processed[feature] = np.log1p(X_test_processed[feature])\n",
    "\n",
    "# 3. Map Hearing column: 1 -> 0, 2 -> 1\n",
    "X_train_processed['hearing(left)'] = X_train_processed['hearing(left)'].map({1: 0, 2: 1})\n",
    "X_train_processed['hearing(right)'] = X_train_processed['hearing(right)'].map({1: 0, 2: 1})\n",
    "X_test_processed['hearing(left)'] = X_test_processed['hearing(left)'].map({1: 0, 2: 1})\n",
    "X_test_processed['hearing(right)'] = X_test_processed['hearing(right)'].map({1: 0, 2: 1})\n",
    "\n",
    "\n",
    "print(f\"Processed training set shape: {X_train_processed.shape}\")\n",
    "print(f\"Processed test set shape: {X_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_pred_proba=None):\n",
    "    \n",
    "    metrics = {}\n",
    "\n",
    "    metrics['Accuracy'] = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    if y_pred_proba is not None:\n",
    "        metrics['AUC Score'] = roc_auc_score(y_true, y_pred_proba)\n",
    "    else:\n",
    "        metrics['AUC Score'] = None  # Will be calculated if probabilities are available\n",
    "    \n",
    "    metrics['Precision'] = precision_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    metrics['Recall'] = recall_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    metrics['F1 Score'] = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    metrics['MCC Score'] = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def display_metrics(model_name, metrics):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        if value is not None:\n",
    "            print(f\"{metric_name:<25} : {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"{metric_name:<25} : Not Available\")\n",
    "    print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15114150",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2706b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_processed, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test_processed)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "lr_metrics = calculate_metrics(y_test, y_pred_lr, y_pred_proba_lr)\n",
    "display_metrics(\"Logistic Regression\", lr_metrics)\n",
    "\n",
    "joblib.dump(lr_model, 'models/logistic_regression_model.pkl')\n",
    "joblib.dump(scaler, 'models/scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab66f45",
   "metadata": {},
   "source": [
    "#### Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7574ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_processed, y_train)\n",
    "\n",
    "y_pred_dt = dt_model.predict(X_test_processed)\n",
    "y_pred_proba_dt = dt_model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "dt_metrics = calculate_metrics(y_test, y_pred_dt, y_pred_proba_dt)\n",
    "display_metrics(\"Decision Tree Classifier\", dt_metrics)\n",
    "\n",
    "joblib.dump(dt_model, 'models/decision_tree_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2514c521",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ebfddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(\n",
    "    n_neighbors=31, \n",
    "    weights='distance', \n",
    "    metric='euclidean', # Standard for scaled data\n",
    "    n_jobs=-1\n",
    ")\n",
    "knn_model.fit(X_train_processed, y_train)\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_test_processed)\n",
    "y_pred_proba_knn = knn_model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "knn_metrics = calculate_metrics(y_test, y_pred_knn, y_pred_proba_knn)\n",
    "display_metrics(\"K-Nearest Neighbor Classifier\", knn_metrics)\n",
    "joblib.dump(knn_model, 'models/knn_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bedfee7",
   "metadata": {},
   "source": [
    "#### Gaussian Nave Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add6f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train_processed, y_train)\n",
    "\n",
    "y_pred_gnb = gnb_model.predict(X_test_processed)\n",
    "y_pred_proba_gnb = gnb_model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "gnb_metrics = calculate_metrics(y_test, y_pred_gnb, y_pred_proba_gnb)\n",
    "display_metrics(\"Gaussian Naive Bayes Classifier\", gnb_metrics)\n",
    "joblib.dump(gnb_model, 'models/gaussian_nb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b1492",
   "metadata": {},
   "source": [
    "#### Ensemble - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_processed, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test_processed)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "rf_metrics = calculate_metrics(y_test, y_pred_rf, y_pred_proba_rf)\n",
    "display_metrics(\"Random Forest Classifier\", rf_metrics)\n",
    "joblib.dump(rf_model, 'models/random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5f9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_train_processed, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test_processed)\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "xgb_metrics = calculate_metrics(y_test, y_pred_xgb, y_pred_proba_xgb)\n",
    "display_metrics(\"XGBoost Classifier\", xgb_metrics)\n",
    "joblib.dump(xgb_model, 'models/xgboost_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
